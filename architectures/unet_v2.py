# -*- coding: utf-8 -*-
"""UNET_V2

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1vvFYLev1Eq0maAteIQMpW1ZdmyAHX-ko
"""

import tensorflow as tf
import numpy as np
import matplotlib.pyplot as plt
import cv2
import os
import PIL
import pandas as pd
import shutil
from PIL import ImageFile
ImageFile.LOAD_TRUNCATED_IMAGES = True
import skimage.io
import skimage.transform as trans
import tensorflow_datasets as tfds
import pathlib

ds, info = tfds.load('oxford_iiit_pet:3.*.*', with_info = True)
#ds_train = tfds.as_numpy(ds_train)
#ds_test = tfds.as_numpy(ds_test)

def normalize(img, mask):
  img /= 255
  mask -= 1
  return img, mask

@tf.function
def load_train_img(datalist):
  image = tf.image.resize(datalist['image'], (256, 256))
  mask = tf.image.resize(datalist['segmentation_mask'], (256, 256))
  image, mask = normalize(image, mask)
  return image, mask

train_set = ds['train'].map(load_train_img, num_parallel_calls=tf.data.experimental.AUTOTUNE)
test_set = ds['test'].map(load_train_img)

train_dataset = train_set.cache().shuffle(1000).batch(16).repeat()
train_dataset = train_dataset.prefetch(buffer_size=tf.data.experimental.AUTOTUNE)
test_dataset = test_set.batch(16)

def get_model(input_size=(256, 256, 3)):
  input_layer = tf.keras.layers.Input(input_size)
  c1 = tf.keras.layers.Conv2D(64, (3,3), padding="same", activation='relu', kernel_initializer='he_normal')(input_layer)
  c2 = tf.keras.layers.Conv2D(64, (3,3), padding="same", activation="relu", kernel_initializer='he_normal')(c1)
  mp1 = tf.keras.layers.MaxPooling2D((2,2))(c2)
  mp1 = tf.keras.layers.Dropout(0.25)(mp1)

  c3 = tf.keras.layers.Conv2D(128, (3,3), padding='same', activation='relu', kernel_initializer='he_normal')(mp1)
  c4 = tf.keras.layers.Conv2D(128, (3,3), padding='same', activation='relu', kernel_initializer='he_normal')(c3)
  mp2 = tf.keras.layers.MaxPooling2D((2,2))(c4)
  mp2 = tf.keras.layers.Dropout(0.5)(mp2)

  c5 = tf.keras.layers.Conv2D(256, (3,3), padding='same', activation='relu', kernel_initializer='he_normal')(mp2)
  c6 = tf.keras.layers.Conv2D(256, (3,3), padding='same', activation='relu', kernel_initializer='he_normal')(c5)
  mp3 = tf.keras.layers.MaxPooling2D((2,2))(c6)
  mp3 = tf.keras.layers.Dropout(0.5)(mp3)

  c7 = tf.keras.layers.Conv2D(512, (3,3), padding='same', activation='relu', kernel_initializer='he_normal')(mp3)
  c8 = tf.keras.layers.Conv2D(512, (3,3), padding='same', activation='relu', kernel_initializer='he_normal')(c7)
  mp4 = tf.keras.layers.MaxPooling2D((2,2))(c8)
  mp4 = tf.keras.layers.Dropout(0.5)(mp4)

  c9 = tf.keras.layers.Conv2D(1024, (3,3), padding='same', activation='relu', kernel_initializer='he_normal')(mp4)
  c10 = tf.keras.layers.Conv2D(1024, (3,3), padding='same', activation='relu', kernel_initializer='he_normal')(c9)

  dc1 = tf.keras.layers.Conv2DTranspose(1024, (3, 3), strides=(2,2), padding='same')(c10)
  concat1 = tf.keras.layers.concatenate([dc1, c8])
  concat1 = tf.keras.layers.Dropout(0.5)(concat1)
  c11 = tf.keras.layers.Conv2D(512, (3,3), padding='same', activation='relu', kernel_initializer='he_normal')(concat1)
  c12 = tf.keras.layers.Conv2D(512, (3,3), padding='same', activation='relu', kernel_initializer='he_normal')(c11)

  dc2 = tf.keras.layers.Conv2DTranspose(512, (3, 3), strides=(2,2), padding='same')(c12)
  concat2 = tf.keras.layers.concatenate([dc2, c6])
  concat2 = tf.keras.layers.Dropout(0.5)(concat2)
  c21 = tf.keras.layers.Conv2D(256, (3,3), padding='same', activation='relu', kernel_initializer='he_normal')(concat2)
  c22 = tf.keras.layers.Conv2D(256, (3,3), padding='same', activation='relu', kernel_initializer='he_normal')(c21)

  dc3 = tf.keras.layers.Conv2DTranspose(256, (3,3), strides=(2,2), padding='same')(c22)
  concat3 = tf.keras.layers.concatenate([dc3, c4])
  concat3 = tf.keras.layers.Dropout(0.5)(concat3)
  c31 = tf.keras.layers.Conv2D(128, (3,3), padding='same', activation='relu', kernel_initializer='he_normal')(concat3)
  c32 = tf.keras.layers.Conv2D(128, (3,3), padding='same', activation='relu', kernel_initializer='he_normal')(c31)

  dc4 = tf.keras.layers.Conv2DTranspose(128, (3,3), strides=(2,2), padding='same')(c32)
  concat4 = tf.keras.layers.concatenate([dc4, c2])
  concat4 = tf.keras.layers.Dropout(0.5)(concat4)
  c41 = tf.keras.layers.Conv2D(64, (3,3), padding='same', activation='relu', kernel_initializer='he_normal')(concat4)
  c42 = tf.keras.layers.Conv2D(64, (3,3), padding='same', activation='relu', kernel_initializer='he_normal')(c41)

  output_layer = tf.keras.layers.Conv2D(1, (1,1), padding="same", activation="linear")(c42)
  
  return input_layer, output_layer

input_layer, output_layer = get_model()
model = tf.keras.models.Model(inputs = [input_layer], outputs = [output_layer])

model.compile(optimizer=tf.keras.optimizers.Adam(lr=0.0001), loss='mse', metrics=["accuracy"])
model.summary()

for image, mask in test_set.take(5):
  image, mask = image, mask
x = model.predict(image[tf.newaxis, ...])

# print(np.amax(x[0]))
# _, mask = cv2.threshold(x[0], 0.6, 1, cv2.THRESH_BINARY)
plt.imshow(x[0].squeeze())
plt.show()
plt.imshow(image)
plt.show()
print("actual mask")
plt.imshow(mask.numpy().squeeze())
plt.show()

STEPS_PER_EPOCH = info.splits['train'].num_examples // 16
EPOCHS = 50
VALIDATION_STEPS = info.splits['test'].num_examples // 16 // 5
save_model = tf.keras.callbacks.ModelCheckpoint("unet_1.h5", monitor='val_accuracy', verbose=1, save_best_only=True, save_weights_only=False, mode='auto', period=1)
early = tf.keras.callbacks.EarlyStopping(monitor='val_accuracy', min_delta=0, patience=10, verbose=1, mode='auto')

hist = model.fit(
    train_dataset,
    epochs = EPOCHS,
    steps_per_epoch = STEPS_PER_EPOCH,
    validation_data = test_dataset,
    validation_steps = VALIDATION_STEPS,
    callbacks = [save_model, early]
)

for image, mask in test_set.take(5):
  image, mask = image, mask
saved_model = tf.keras.models.load_model("unet_1.h5")
pred_mask = saved_model.predict(image[tf.newaxis, ...])
plt.imshow(pred_mask[0].squeeze())
plt.show()
plt.imshow(image)
plt.show()
print("actual mask")
plt.imshow(mask.numpy().squeeze())
plt.show()

loss = hist.history['loss']
val_loss = hist.history['val_loss']

epochs = range(30)

plt.figure()
plt.plot(epochs, loss, 'r', label='Training loss')
plt.plot(epochs, val_loss, 'bo', label='Validation loss')
plt.title('Training and Validation Loss')
plt.xlabel('Epoch')
plt.ylabel('Loss Value')
plt.ylim([0, 1])
plt.legend()
plt.show()